{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7. Parallel Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With parallel processing by using multiple cores, you can increase the amount of calculations your program can do in a given time frame without needing a faster processor. The main idea is to divide a problem into independent subunits and use multiple cores to solve those subunits in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing is necessary to tackle large-scale problems. Companies produce massive quantities of data every day that need to be stored in multiple computers and analyzed. Scientists and engineers run parallel code on supercomputers to simulate massive systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing allows you to take advantage of multicore CPUs as well as GPUs that work extremely well with highly parallel problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 7.1 Introduction to parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to parallelize a program, it is necessary to divide the problem into subunits that can \"run independently (or almost independently) from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem where the subunits are totally independent from each other is called embarrassingly parallel. An element-wise operation on an array is a typical example--the operation needs to only know the element it is handling at the moment.Embarrassingly parallel problems are very easy to implement and perform very well on parallel architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other problems may be divided into subunits but have to share some data to perform their calculations. In those cases, the implementation is less straightforward and can lead to performance issues because of the communication costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Communication between processes is costly and can seriously hinder the performance of parallel programs. There exist two main ways to handle data communication in parallel programs:\n",
    "1. **Shared memory**\n",
    "2. **Distributed memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In shared memory, the subunits have access to the same memory space. The advantage of this approach is that you don't have to explicitly handle the communication as it is sufficient to write or read from the shared memory. However, problems arise when multiple processes try to access and change the same memory location at the same time. Care should be taken to avoid such conflict using synchronization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the distributed memory model, each process is completely separated from the others and possesses its own memory space. In this case, communication is handled explicitly between the processes. The communication overhead is typically costlier compared to shared memory as data can potentially travel through a network interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python can spawn and handle threads, but they can't be used to increase performance; due to the Python interpreter design, only one Python instruction is allowed to run at a time-- this mechanism is called **Global Interpreter Lock (GIL)**. What happens is that each time a thread executes a Python statement, the thread acquires a lock and, when the execution is completed, the same lock is released. Since the lock can be acquired only by one thread at a time, other threads are prevented from executing Python statements while some other thread holds the lock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the GIL prevents parallel execution of Python instructions, threads can still be used to provide concurrency in situations where the lock can be released, such as in timeconsuming I/O operations or in C extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GIL can be completely sidestepped using processes instead of threads. Processes don't share the same memory area and are independent from each other--each process has its own interpreter. Processes have a few disadvantages: starting up a new process is generally slower than starting a new thread, they consume more memory, and inter-process communication can be slow. On the other hand, processes are still very flexible, and they scale better as they can be distributed on multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Graphic processing units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphic processing units are special processors designed for computer graphics applications. Those applications usually require processing the geometry of a 3D scene and output an array of pixel to the screen. The operations performed by GPUs involve array and matrix operations on floating point numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs are designed to run this graphics-related operation very efficiently, and they achieve this by adopting a highly parallel architecture. Compared to a CPU, a GPU has many more\n",
    "(thousands) of small processing units. GPUs are intended to produce data at about 60 frames per second, which is much slower than the typical response time of a CPU, which possesses higher clock speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs possess a very different architecture from a standard CPU and are specialized for computing floating point operations. Therefore, to compile programs for GPUs, it is necessary to utilize special programming platforms, such as CUDA and OpenCL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Unified Device Architecture (CUDA)** is a proprietary NVIDIA technology. It provides an API that can be accessed from other languages. CUDA provides the NVCC tool that can be used to compile GPU programs written in a language similar to C (CUDA C) as well as numerous libraries that implement highly optimized mathematical routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenCL** is an open technology with the ability of writing parallel programs that can be compiled for a variety of target devices (CPUs and GPUs of several vendors) and is a good option for non-NVIDIA devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU programming is tricky and only specific use cases benefit from the GPU architecture. Programmers need to be aware of the costs incurred in memory transfers to and from the main memory and how to implement algorithms to take advantage of the GPU architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs are great at increasing the amount of operations you can perform per unit of time (also called throughput); however, they require more time to prepare the data for processing. In contrast, CPUs are much faster at producing an individual result from scratch (also called latency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 7.2 Using multiple processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard multiprocessing module can be used to quickly parallelize simple tasks by spawning several processes, while avoiding the GIL problem. Its interface is easy to use and includes several utilities to handle task submission and synchronization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 The process and pool classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm the process with id: 0\n",
      "I'm the process with id: 0\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing \n",
    "import time \n",
    "\n",
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, id):\n",
    "        super(Process, self).__init__()\n",
    "        self.id = id\n",
    "    def run(self):\n",
    "        time.sleep(1)\n",
    "        print(\"I'm the process with id: {}\".format(self.id))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(0)\n",
    "    p.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(0)\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm the process with id: 1\n",
      "I'm the process with id: 2\n",
      "I'm the process with id: 3\n",
      "I'm the process with id: 4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    processes = Process(1), Process(2), Process(3), Process(4)\n",
    "    [p.start() for p in processes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiprocessing module exposes a convenient interface that makes it easy to assign and distribute tasks to a set of processes that reside in the multiprocessing.Pool class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiprocessing.Pool class spawns a set of processes--called workers--and lets us submit tasks through the apply/apply_async and map/map_async methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pool.map method applies a function to each element of a list and returns the list of results. Its usage is equivalent to the built-in (serial) map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "pool = multiprocessing.Pool(processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "inputs = [0,1,2,3,4]\n",
    "outputs = pool.map(square, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_async = pool.map_async(square, inputs)\n",
    "outputs = outputs_async.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_async = [pool.apply_async(square, i) for i in range(100))]\n",
    "results = [r.get() for r in results_async]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 The executor interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "executor = ProcessPoolExecutor(max_workers=4)\n",
    "fut = executor.submit(square, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = executor.map(square, [0, 1, 2, 3, 4])\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import wait, as_completed\n",
    "\n",
    "fut1 = executor.submit(square, 2)\n",
    "fut2 = executor.submit(square, 3)\n",
    "wait([fut1, fut2])\n",
    "\n",
    "# Then you can extract the results using fut1.result() and fut2.result()\n",
    "results = as_completed([fut1, fut2])\n",
    "list(results)\n",
    "# Result:\n",
    "# [4, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 Monte carlo approximation of pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits/total = area_circle/area_square = pi/4\n",
    "pi = 4 * hits/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "samples = 1000000\n",
    "hits = 0\n",
    "\n",
    "for i in range(samples):\n",
    "    x = random.uniform(-1.0, 1.0)\n",
    "    y = random.uniform(-1.0, 1.0)\n",
    "    if x**2 + y**2 <= 1:\n",
    "        hits += 1\n",
    "pi = 4.0 * hits/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def sample():\n",
    "    x = random.uniform(-1.0, 1.0)\n",
    "    y = random.uniform(-1.0, 1.0)\n",
    "    if x**2 + y**2 <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "pool = multiprocessing.Pool()\n",
    "results_async = [pool.apply_async(sample) for i in range(samples)]\n",
    "hits = sum(r.get() for r in results_async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m5.820s\n",
      "user\t0m5.747s\n",
      "sys\t0m0.030s\n"
     ]
    }
   ],
   "source": [
    "!time python -c 'import pi; pi.pi_serial()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t8m35.980s\n",
      "user\t10m52.730s\n",
      "sys\t5m38.677s\n"
     ]
    }
   ],
   "source": [
    "!time python -c 'import pi; pi.pi_apply_async()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multiple(samples_partial):\n",
    "    return sum(sample() for i in range(samples_partial))\n",
    "n_tasks = 10\n",
    "chunk_size = samples/n_tasks\n",
    "pool = multiprocessing.Pool()\n",
    "results_async = [pool.apply_async(sample_multiple, chunk_size)\n",
    "                 for i in range(n_tasks)]\n",
    "hits = sum(r.get() for r in results_async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/boyuan/anaconda3/envs/Python/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/boyuan/Desktop/OneDrive/Data science/Python/Python high performance 2nd/Python-High-Performance-Second-Edition-master/Chapter07/pi.py\", line 38, in sample_multiple\n",
      "    return sum(sample() for i in range(samples_partial))\n",
      "TypeError: 'float' object cannot be interpreted as an integer\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/boyuan/Desktop/OneDrive/Data science/Python/Python high performance 2nd/Python-High-Performance-Second-Edition-master/Chapter07/pi.py\", line 46, in pi_apply_async_chunked\n",
      "    hits = sum(r.get() for r in results_async)\n",
      "  File \"/Users/boyuan/Desktop/OneDrive/Data science/Python/Python high performance 2nd/Python-High-Performance-Second-Edition-master/Chapter07/pi.py\", line 46, in <genexpr>\n",
      "    hits = sum(r.get() for r in results_async)\n",
      "  File \"/Users/boyuan/anaconda3/envs/Python/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n",
      "    raise self._value\n",
      "TypeError: 'float' object cannot be interpreted as an integer\n",
      "\n",
      "real\t0m0.206s\n",
      "user\t0m0.083s\n",
      "sys\t0m0.067s\n"
     ]
    }
   ],
   "source": [
    "!time python -c 'import pi; pi.pi_apply_async_chunked()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 Synchronization and locks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_variable = multiprocessing.Value('f')\n",
    "shared_variable.value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, counter):\n",
    "        super(Process, self).__init__()\n",
    "        self.counter = counter\n",
    "    def run(self):\n",
    "        for i in range(1000):\n",
    "            self.counter.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    counter = multiprocessing.Value('i', lock=True)\n",
    "    counter.value = 0\n",
    "    processes = [Process(counter) for i in range(4)]\n",
    "    [p.start() for p in processes]\n",
    "    [p.join() for p in processes] # processes are done\n",
    "    print(counter.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the lock can be acquired by only one process at a time, this method prevents multiple processes from executing the protected section of code at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = multiprocessing.Lock()\n",
    "\n",
    "class Process(multiprocessing.Process):\n",
    "    def __init__(self, counter):\n",
    "        super(Process, self).__init__()\n",
    "        self.counter = counter\n",
    "    def run(self):\n",
    "        for i in range(1000):\n",
    "            with lock: # acquire the lock\n",
    "                 self.counter.value += 1\n",
    "            # release the lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 7.3 Parallel Cython with OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def square_serial(double[:] inp):\n",
    "    cdef int i, size\n",
    "    cdef double[:] out\n",
    "    size = inp.shape[0]\n",
    "    out_np = np.empty(size, 'double')\n",
    "    out = out_np\n",
    "    \n",
    "    for i in range(size):\n",
    "        out[i] = inp[i]*inp[i]\n",
    "    return out_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nogil:\n",
    "    for i in prange(size):\n",
    "        out[i] = inp[i]*inp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in prange(size, nogil=True):\n",
    "    out[i] = inp[i]*inp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in prange(size, nogil=True):\n",
    "    out[i] = inp[i]*inp[i]\n",
    "    with gil:\n",
    "        x = 0 # Python assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.core import setup\n",
    "from distutils.extension import Extension\n",
    "from Cython.Build import cythonize\n",
    "hello_parallel = Extension('hello_parallel',\n",
    "['hello_parallel.pyx'],\n",
    "extra_compile_args=['-fopenmp'],\n",
    "extra_link_args=['-fopenmp'])\n",
    "setup(\n",
    "name='Hello',\n",
    "ext_modules = cythonize(['cevolve.pyx', hello_parallel]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_evolve(double[:, :] r_i,double[:] ang_speed_i,\n",
    "    double timestep,int nsteps):\n",
    "# cdef declarations\n",
    "for i in range(nsteps):\n",
    "    for j in range(nparticles):\n",
    "        # loop body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(nparticles):\n",
    "    for i in range(nsteps):\n",
    "# loop body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in prange(nparticles, nogil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit benchmark(10000, 'openmp') # Running on 4 processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit benchmark(10000, 'cython')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 7.4 Automatic parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theano** is a project that allows you to define a mathematical expression on arrays (more generally, tensors), and compile them to a fast language, such as C or C++. Many of the operations that Theano implements are parallelizable and can run on both CPU and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow** is another library that, similar to Theano, is targeted towards expression of array-intensive mathematical expression but, rather than translating the expressions to specialized C code, executes the operations on an efficient C++ engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Theano and Tensorflow are ideal when the problem at hand can be expressed in a chain of matrix and element-wise operations (such as neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.1 Getting started with Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano is somewhat similar to a compiler but with the added bonuses of being able to express, manipulate, and optimize mathematical expressions as well as run code on CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "import theano as th\n",
    "a = T.scalar('a')\n",
    "a_sq = a ** 2\n",
    "print(a_sq)\n",
    "# Output:\n",
    "# Elemwise{pow,no_inplace}.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_square = th.function([a], a_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_square(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = T.vector('a')\n",
    "b = T.vector('b')\n",
    "ab_sq = a**2 + b**2\n",
    "compute_square = th.function([a, b], ab_sq)\n",
    "compute_square([0, 1, 2], [3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.vector('x')\n",
    "y = T.vector('y')\n",
    "hit_test = x ** 2 + y ** 2 < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = hit_test.sum()\n",
    "total = x.shape[0]\n",
    "pi_est = 4 * hits/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_pi = th.function([x, y], pi_est)\n",
    "x_val = np.random.uniform(-1, 1, 30000)\n",
    "y_val = np.random.uniform(-1, 1, 30000)\n",
    "import timeit\n",
    "res = timeit.timeit(\"calculate_pi(x_val, y_val)\",\n",
    "\"from __main__ import x_val, y_val, calculate_pi\", number=100000)\n",
    "print(res)\n",
    "# Output:\n",
    "# 10.905971487998613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "theano.config.openmp = True\n",
    "theano.config.openmp_elemwise_minsize = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow works by building mathematical expressions similar to Theano, except that the computation is not compiled to machine code but is executed on an external engine written in C++. Tensorflow supports execution and deployment of parallel codes on one or more CPUs and GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.placeholder('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow doesn't compile functions to C and then machine code like Theano, but serializes the defined mathematical functions (the data structure containing variables and transformations is called computation graph) and executes them on specific devices. The configuration of devices and context can be done using the tf.Session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder('float64')\n",
    "b = tf.placeholder('float64')\n",
    "ab_sq = a**2 + b**2\n",
    "with tf.Session() as session:\n",
    "    result = session.run(ab_sq, feed_dict={a: [0, 1, 2],\n",
    "                                            b: [3, 4, 5]})\n",
    "print(result)\n",
    "# Output:\n",
    "# array([ 9., 17., 29.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTEL MKL ERROR: dlopen(/Users/boyuan/anaconda3/envs/Python/lib/libmkl_intel_thread.dylib, 9): Library not loaded: @rpath/libiomp5.dylib\n",
      "  Referenced from: /Users/boyuan/anaconda3/envs/Python/lib/libmkl_intel_thread.dylib\n",
      "  Reason: image not found.\n",
      "Intel MKL FATAL ERROR: Cannot load libmkl_intel_thread.dylib.\n"
     ]
    }
   ],
   "source": [
    "!python test_tensorflow.py 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of using software packages such as Tensorflow and Theano is the support for parallel matrix operations that are commonly used in machine learning algorithms. This is very effective because those operations can achieve impressive performance gains on GPU hardware that is designed to perform these operations with high throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 Running code on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'test_theano_gpu.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!THEANO_FLAGS=device=gpu python test_theano_gpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTEL MKL ERROR: dlopen(/Users/boyuan/anaconda3/envs/Python/lib/libmkl_intel_thread.dylib, 9): Library not loaded: @rpath/libiomp5.dylib\n",
      "  Referenced from: /Users/boyuan/anaconda3/envs/Python/lib/libmkl_intel_thread.dylib\n",
      "  Reason: image not found.\n",
      "Intel MKL FATAL ERROR: Cannot load libmkl_intel_thread.dylib.\n"
     ]
    }
   ],
   "source": [
    "!THEANO_FLAGS=device=cpu python test_theano.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 7.5 Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
